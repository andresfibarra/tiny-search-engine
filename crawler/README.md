# Andres Ibarra
## CS50 Spring 2021, Lab 4 TSE Crawler

GitHub username: @andresfibarra

### Instructions

To build, run `make` in terminal

To clean up make-derived files, run `make clean`

Run `testing.sh` on a Dartmouth linux machine


### Usage

./crawler seedURL pageDirectory maxDepth

if `seedURL` is the webpage crawler is initially pointed at, `pageDirectory` is the directory to while files will be saved, and `maxDepth` is the maximum number of "jumps" the crawler will make while scanning for new pages

### Assumptions

No assumptions other than those specified in the requirements